## Pehchaan-TIFR

## Touchless two factor authentication based Attendance System

Pehchaan-TIFR is an automated face recognition-based attendance system designed for Tata Institute of Fundamental Research (TIFR).It leverages facial recognition and voice verification to automate attendance tracking, ensuring accuracy and security.

## Dataset

The system processes two types of biometric data:
1Ô∏è‚É£ Facial Data: Images of individuals for face recognition.
2Ô∏è‚É£ Voice Data: Recorded voice samples for speaker verification.

The system uses a custom dataset collected from users during enrollment, extracting unique facial embeddings and voice features for authentication.

## Theory

1Ô∏è‚É£ Facial Feature Extraction
	‚Ä¢	Face Detection: Identify faces using Haar cascades or CNN-based models.
	‚Ä¢	Feature Encoding: Extract unique facial embeddings using Dlib‚Äôs FaceNet.
	‚Ä¢	Face Matching: Compare facial embeddings with stored templates using Euclidean distance.

2Ô∏è‚É£ Voice Feature Extraction
	‚Ä¢	Preprocessing: Remove noise and normalize audio signals.
	‚Ä¢	Feature Extraction: Use Mel-Frequency Cepstral Coefficients (MFCCs) to analyze voice patterns.
	‚Ä¢	Speaker Recognition: Identify individuals using a Gaussian Mixture Model (GMM) trained on voice data.

#### Workflow Graph

1Ô∏è‚É£ Image & Voice Capture  
 ‚Üí  2Ô∏è‚É£ Face & Voice Detection  
   ‚Üí  3Ô∏è‚É£ Feature Extraction (Facial Embeddings & MFCCs)  
     ‚Üí  4Ô∏è‚É£ Face & Voice Recognition  
       ‚Üí  5Ô∏è‚É£ Attendance Logging  

## Dependencies

This project requires the following Python libraries:
	‚Ä¢	OpenCV (Face Detection & Processing)
	‚Ä¢	Dlib (Facial Feature Extraction)
	‚Ä¢	Face Recognition Library (Deep Learning-based Face Matching)
	‚Ä¢	Librosa & Python Speech Features (Voice Processing & Feature Extraction)
	‚Ä¢	Flask/FastAPI (Backend API)
	‚Ä¢	SQLite/MySQL (Attendance Database)

## Results

The system was tested on a dataset of 100+ individuals, achieving:
	‚Ä¢	Face Recognition Accuracy: 96.8%
	‚Ä¢	Voice Recognition Accuracy: 94.5%
	‚Ä¢	Response Time: < 2 seconds per user

## Installation & Usage

	#### 1.	Clone the repository
		```
		git clone https://github.com/hegdeshreya23/Pehchaan-TIFR.git
		cd Pehchaan-TIFR
		```

	#### 2.	Install dependencies
		```
		pip install -r requirements.txt
		
		```
	3.	Run the application
		```
		python app.py
		
		```
	4.	Enroll Users (Face & Voice Registration)
		‚Ä¢	Upload images and record a short speech sample.
		‚Ä¢	The system extracts and stores facial embeddings & voice features.
	5.	Start Attendance Recognition
		‚Ä¢	The system captures a user‚Äôs face and voice.
		‚Ä¢	If both match stored data, attendance is logged automatically.
Here‚Äôs your GitHub README with improved formatting and proper alignment for better readability:

Pehchaan-TIFR

Touchless Two-Factor Authentication-Based Attendance System

Pehchaan-TIFR is an automated face and voice recognition-based attendance system designed for Tata Institute of Fundamental Research (TIFR). It leverages facial recognition and voice verification to automate attendance tracking, ensuring accuracy and security.

Dataset

The system processes two types of biometric data:

‚úÖ Facial Data: Images of individuals for face recognition.
‚úÖ Voice Data: Recorded voice samples for speaker verification.

The system uses a custom dataset collected from users during enrollment, extracting unique facial embeddings and voice features for authentication.

Theory

1Ô∏è‚É£ Facial Feature Extraction
	‚Ä¢	Face Detection: Identify faces using Haar cascades or CNN-based models.
	‚Ä¢	Feature Encoding: Extract unique facial embeddings using Dlib‚Äôs FaceNet.
	‚Ä¢	Face Matching: Compare facial embeddings with stored templates using Euclidean distance.

2Ô∏è‚É£ Voice Feature Extraction
	‚Ä¢	Preprocessing: Remove noise and normalize audio signals.
	‚Ä¢	Feature Extraction: Use Mel-Frequency Cepstral Coefficients (MFCCs) to analyze voice patterns.
	‚Ä¢	Speaker Recognition: Identify individuals using a Gaussian Mixture Model (GMM) trained on voice data.

Workflow Graph

1Ô∏è‚É£ Image & Voice Capture  
 ‚Üí  2Ô∏è‚É£ Face & Voice Detection  
   ‚Üí  3Ô∏è‚É£ Feature Extraction (Facial Embeddings & MFCCs)  
     ‚Üí  4Ô∏è‚É£ Face & Voice Recognition  
       ‚Üí  5Ô∏è‚É£ Attendance Logging  

Dependencies

This project requires the following Python libraries:
	‚Ä¢	OpenCV (Face Detection & Processing)
	‚Ä¢	Dlib (Facial Feature Extraction)
	‚Ä¢	Face Recognition Library (Deep Learning-based Face Matching)
	‚Ä¢	Librosa & Python Speech Features (Voice Processing & Feature Extraction)
	‚Ä¢	Flask/FastAPI (Backend API)
	‚Ä¢	SQLite/MySQL (Attendance Database)

Results

The system was tested on a dataset of 100+ individuals, achieving:
	‚Ä¢	Face Recognition Accuracy: 96.8%
	‚Ä¢	Voice Recognition Accuracy: 94.5%
	‚Ä¢	Response Time: < 2 seconds per user

Installation & Usage

1Ô∏è‚É£ Clone the repository

git clone https://github.com/hegdeshreya23/Pehchaan-TIFR.git
cd Pehchaan-TIFR

2Ô∏è‚É£ Install dependencies

pip install -r requirements.txt

3Ô∏è‚É£ Run the application

python app.py

4Ô∏è‚É£ Enroll Users (Face & Voice Registration)
	‚Ä¢	Upload images and record a short speech sample.
	‚Ä¢	The system extracts and stores facial embeddings & voice features.

5Ô∏è‚É£ Start Attendance Recognition
	‚Ä¢	The system captures a user‚Äôs face and voice.
	‚Ä¢	If both match stored data, attendance is logged automatically.

This formatting ensures a clean and structured README for GitHub. Let me know if you need further refinements! üöÄ
